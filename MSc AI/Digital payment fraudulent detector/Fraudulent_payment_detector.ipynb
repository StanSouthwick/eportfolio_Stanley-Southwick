{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9020e96",
   "metadata": {},
   "source": [
    "This project is aimed to create an sophisticated ML algorithm using logistic regression to categorise pyaments to detect whetehr they are fraudulent or not.\n",
    "\n",
    "Throuhgout this project I will be showcasing learnt techniques to load the data in the form of CSV\n",
    "Using EDA to critically analyse the data and decide on features and eploit any bias or variance within the dataset.\n",
    "Then using Schikit-learn to preprocess and split the data.\n",
    "Fitting the model and the tetsing and evaluating the model to ensure the highest accuracy is achieved whilst maintaining a good balance of not over/underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c22a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all relevant modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "digital_payment_dataset = pd.read_csv('Digital_Payment_Fraud_Detection_Dataset.csv')\n",
    "# Displaying the first few rows of the dataset\n",
    "#print(digital_payment_dataset.head())\n",
    "#print(digital_payment_dataset.info())\n",
    "#print(digital_payment_dataset.describe())\n",
    "\n",
    "# Split into features and target variable\n",
    "x = digital_payment_dataset.drop('fraud_label', axis=1)\n",
    "y = digital_payment_dataset['fraud_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578ee08",
   "metadata": {},
   "source": [
    "Splitting the dataset into training and testing splits in order to training the model then use totally unseen data to criticallly analyse its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a8bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03aeed",
   "metadata": {},
   "source": [
    "I will now carry out some EDA, exploratory data analysis, to visualise the distribution on the dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
